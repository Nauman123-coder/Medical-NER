{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Medical Named Entity Recognition (NER) Project\n",
        "\n",
        "## Overview\n",
        "\n",
        "This project implements a medical Named Entity Recognition (NER) system using two approaches:\n",
        "\n",
        "1. **Custom spaCy Model Training**: Training a custom NER model from scratch using annotated medical text data\n",
        "2. **Pre-trained Transformer Model**: Using a pre-trained biomedical NER model from Hugging Face\n",
        "\n",
        "The system is designed to identify and extract medical entities from clinical text, including:\n",
        "- **Medications**: Drug names and prescriptions (e.g., Aspirin, Metformin, Warfarin)\n",
        "- **Diseases**: Medical conditions and diagnoses (e.g., diabetes, pneumonia, COPD)\n",
        "- **Treatments**: Medical procedures and therapies (e.g., surgery, inhaler therapy)\n",
        "\n",
        "## Project Structure\n",
        "\n",
        "The code is divided into the following sections:\n",
        "\n",
        "1. **Data Loading and Exploration** - Uploading and examining the annotated JSON dataset\n",
        "2. **Data Preprocessing** - Converting JSON annotations to spaCy training format\n",
        "3. **spaCy Training Data Preparation** - Creating spaCy DocBin format for model training\n",
        "4. **Model Training** - Training a custom spaCy NER model\n",
        "5. **Model Inference (spaCy)** - Testing the trained model on sample medical text\n",
        "6. **Transformer Model Inference** - Using a pre-trained biomedical NER model\n",
        "\n",
        "## Use Cases\n",
        "\n",
        "- Automated extraction of medical information from clinical notes\n",
        "- Medical record processing and analysis\n",
        "- Drug-disease relationship extraction\n",
        "- Clinical decision support systems\n",
        "\n",
        "## Technologies Used\n",
        "\n",
        "- **spaCy**: For custom NER model training and inference\n",
        "- **Transformers (Hugging Face)**: For pre-trained biomedical NER\n",
        "- **Pandas**: For data manipulation\n",
        "- **PyTorch**: Backend for transformer models\n",
        "- **Google Colab**: Development environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 1: Data Loading and Exploration\n",
        "\n",
        "This section handles uploading the annotated medical dataset and performing initial exploration to understand the data structure.\n",
        "\n",
        "### 1. File Upload and JSON Loading\n",
        "\n",
        "- **File Upload**: Uses Google Colab's `files.upload()` to allow users to upload files from their local computer\n",
        "- **JSON Loading**: Reads the `Corona2.json` file which contains annotated medical text data\n",
        "- **Data Type Check**: Prints the type of the loaded data to verify it's properly loaded as a dictionary or list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "85AFi0sNNdzv",
        "outputId": "7c48d60a-0a0b-47f2-bb7b-fa8b1d221884"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b0c9d0ae-2189-46de-89b1-b098aba9800c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b0c9d0ae-2189-46de-89b1-b098aba9800c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving Corona2.json to Corona2.json\n",
            "<class 'dict'>\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Upload file from your computer\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load JSON file (replace with your actual filename after upload)\n",
        "with open(\"Corona2.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(type(data))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Library Imports\n",
        "Imports essential libraries for:\n",
        "- Data manipulation (numpy, pandas)\n",
        "- Visualization (matplotlib, seaborn)\n",
        "- NLP processing (nltk, spacy)\n",
        "- Progress tracking (tqdm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "41m3Z6xpOGjN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import nltk\n",
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. File System Exploration\n",
        "- Walks through the file system to verify the uploaded file location\n",
        "- Prints all files found in the specified path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "h0MLIttcObm6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk(\"/content/Corona2.json\"):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Load JSON as DataFrame\n",
        "- Loads the JSON file into a pandas DataFrame for easier manipulation\n",
        "- Displays the first 5 rows to preview the data structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JQqhFhAfOo1T",
        "outputId": "e89e18f1-2190-4a7e-a294-96c7ff449171"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 31,\n  \"fields\": [\n    {\n      \"column\": \"examples\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7055cc09-2c65-4cea-be17-1a246cd3a969\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>examples</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'id': '18c2f619-f102-452f-ab81-d26f7e283ffe',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'id': '487c93e3-0d45-4088-a378-cf3a01c8953d',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'id': 'd5056874-895a-4a7f-9e0f-828d414d65d9',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'id': '20c792c7-0c4b-42d0-8127-0e04113db384',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'id': 'f5359e0d-4d4a-4707-95a3-4c627fc4a83b',...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7055cc09-2c65-4cea-be17-1a246cd3a969')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7055cc09-2c65-4cea-be17-1a246cd3a969 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7055cc09-2c65-4cea-be17-1a246cd3a969');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-097636f8-9e63-4f60-bf0a-b44d33472a23\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-097636f8-9e63-4f60-bf0a-b44d33472a23')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-097636f8-9e63-4f60-bf0a-b44d33472a23 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                            examples\n",
              "0  {'id': '18c2f619-f102-452f-ab81-d26f7e283ffe',...\n",
              "1  {'id': '487c93e3-0d45-4088-a378-cf3a01c8953d',...\n",
              "2  {'id': 'd5056874-895a-4a7f-9e0f-828d414d65d9',...\n",
              "3  {'id': '20c792c7-0c4b-42d0-8127-0e04113db384',...\n",
              "4  {'id': 'f5359e0d-4d4a-4707-95a3-4c627fc4a83b',..."
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = \"/content/Corona2.json\"\n",
        "\n",
        "data = pd.read_json(path)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Data Structure Exploration\n",
        "- **Keys Inspection**: Lists all keys in the first example to understand available fields\n",
        "- **Content Display**: Shows the actual text content of the first training example\n",
        "- **Annotations Display**: Examines the structure of annotations (entity labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raKxQaGgOxdd",
        "outputId": "8ef4aa74-18c1-4052-d005-f3bf3f4796e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['id', 'content', 'metadata', 'annotations', 'classifications']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(data['examples'][0].keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "kcmZwW4bO08k",
        "outputId": "a66fd195-9ddb-408a-bee0-9ea9c4dca5f8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"While bismuth compounds (Pepto-Bismol) decreased the number of bowel movements in those with travelers' diarrhea, they do not decrease the length of illness.[91] Anti-motility agents like loperamide are also effective at reducing the number of stools but not the duration of disease.[8] These agents should be used only if bloody diarrhea is not present.[92]\\n\\nDiosmectite, a natural aluminomagnesium silicate clay, is effective in alleviating symptoms of acute diarrhea in children,[93] and also has some effects in chronic functional diarrhea, radiation-induced diarrhea, and chemotherapy-induced diarrhea.[45] Another absorbent agent used for the treatment of mild diarrhea is kaopectate.\\n\\nRacecadotril an antisecretory medication may be used to treat diarrhea in children and adults.[86] It has better tolerability than loperamide, as it causes less constipation and flatulence.[94]\""
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['examples'][0]['content']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW80qBl1O00h",
        "outputId": "8bef4285-ecd9-4a52-e504-2f488b38f01a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': '0825a1bf-6a6e-4fa2-be77-8d104701eaed',\n",
              " 'tag_id': 'c06bd022-6ded-44a5-8d90-f17685bb85a1',\n",
              " 'end': 371,\n",
              " 'start': 360,\n",
              " 'example_id': '18c2f619-f102-452f-ab81-d26f7e283ffe',\n",
              " 'tag_name': 'Medicine',\n",
              " 'value': 'Diosmectite',\n",
              " 'correct': None,\n",
              " 'human_annotations': [{'timestamp': '2020-03-21T00:24:32.098000Z',\n",
              "   'annotator_id': 1,\n",
              "   'tagged_token_id': '0825a1bf-6a6e-4fa2-be77-8d104701eaed',\n",
              "   'name': 'Ashpat123',\n",
              "   'reason': 'exploration'}],\n",
              " 'model_annotations': []}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['examples'][0]['annotations'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 2: Data Preprocessing\n",
        "This section transforms the JSON-formatted annotations into the format required for spaCy NER model training.\n",
        "\n",
        "### Converting JSON to spaCy Training Format\n",
        "**Transformation Process**:\n",
        "1. **Iterates through all examples** in the dataset\n",
        "2. **Extracts text content** from each example's `content` field\n",
        "3. **Processes annotations** by:\n",
        "   - Getting the character start position (`annotation['start']`)\n",
        "   - Getting the character end position (`annotation['end']`)\n",
        "   - Converting tag names to uppercase (`annotation['tag_name'].upper()`)\n",
        "4. **Creates tuples** in the format: `(start, end, label)`\n",
        "5. **Stores in dictionary** with keys `text` and `entities`\n",
        "\n",
        "### Data Validation\n",
        "**Verification Steps**:\n",
        "- **Displays entities** from the first training example to verify correct format\n",
        "- **Extracts text slice** using the character positions to confirm that the annotations align correctly with the actual text\n",
        "- This helps catch any misalignment issues between annotations and text\n",
        "\n",
        "## Why This Format?\n",
        "spaCy's NER training requires:\n",
        "- Plain text strings\n",
        "- Entity annotations as tuples of (start_char, end_char, label)\n",
        "- Labels in uppercase by convention\n",
        "\n",
        "This preprocessing step bridges the gap between your annotated dataset and spaCy's expected input format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "shrYaSpWO0t4"
      },
      "outputs": [],
      "source": [
        "training_data = [\n",
        "    {\n",
        "        'text': example['content'],\n",
        "        'entities': [\n",
        "            (annotation['start'], annotation['end'], annotation['tag_name'].upper())\n",
        "            for annotation in example['annotations']\n",
        "        ]\n",
        "    }\n",
        "    for example in data['examples']\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlSgxY_APDIn",
        "outputId": "724ccb66-438b-484f-d354-175ad11509a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(360, 371, 'MEDICINE'),\n",
              " (383, 408, 'MEDICINE'),\n",
              " (104, 112, 'MEDICALCONDITION'),\n",
              " (679, 689, 'MEDICINE'),\n",
              " (6, 23, 'MEDICINE'),\n",
              " (25, 37, 'MEDICINE'),\n",
              " (461, 470, 'MEDICALCONDITION'),\n",
              " (577, 589, 'MEDICINE'),\n",
              " (853, 865, 'MEDICALCONDITION'),\n",
              " (188, 198, 'MEDICINE'),\n",
              " (754, 762, 'MEDICALCONDITION'),\n",
              " (870, 880, 'MEDICALCONDITION'),\n",
              " (823, 833, 'MEDICINE'),\n",
              " (852, 853, 'MEDICALCONDITION'),\n",
              " (461, 469, 'MEDICALCONDITION'),\n",
              " (535, 543, 'MEDICALCONDITION'),\n",
              " (692, 704, 'MEDICINE'),\n",
              " (563, 571, 'MEDICALCONDITION')]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data[0]['entities']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Yo9t4lY-PHGv",
        "outputId": "bbf9a91f-e6d8-4521-f4e7-5a27985f433a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'diarrhea'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data[0]['text'][563:571]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 3: spaCy Training Data Preparation\n",
        "This section converts the preprocessed training data into spaCy's binary format (DocBin), which is required for efficient model training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Initialize spaCy Components\n",
        "- **`spacy.blank(\"en\")`**: Creates a blank English language model without any pre-trained components\n",
        "- **`DocBin()`**: Initializes a container for efficiently storing spaCy Doc objects in binary format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Dp-_A5mWPKJ3"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "doc_bin = DocBin()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Import Entity Filtering Utility\n",
        "- Imports a utility function to handle overlapping entity spans\n",
        "- Ensures that no two entities overlap in the same text, which would cause training errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jRJCw5TWPKCA"
      },
      "outputs": [],
      "source": [
        "from spacy.util import filter_spans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Process Training Examples\n",
        "**Step-by-Step Process**:\n",
        "\n",
        "1. **Loop through training data**: Uses `tqdm` for progress bar visualization\n",
        "\n",
        "2. **Extract text and labels**: Gets the text content and entity annotations from each example\n",
        "\n",
        "3. **Create Doc object**: Converts raw text into a spaCy Doc object with tokenization\n",
        "\n",
        "4. **Process each entity**:\n",
        "   - **`char_span()`**: Creates a Span object from character positions\n",
        "   - **`alignment_mode=\"contract\"`**: If tokens don't align perfectly with character positions, contract the span to fit token boundaries\n",
        "   - **Error handling**: Skips entities that can't be aligned (prints \"Skipping entity\")\n",
        "   - **Append valid spans**: Adds successfully created spans to the list\n",
        "\n",
        "5. **Filter overlapping spans**: Removes any overlapping entities, keeping the longest/most specific ones\n",
        "\n",
        "6. **Set entities**: Assigns the filtered entities to the Doc object\n",
        "\n",
        "7. **Add to DocBin**: Stores the processed Doc in the binary container\n",
        "\n",
        "8. **Save to disk**: Writes the entire DocBin to `train.spacy` file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Asd8wiRoPJ5x",
        "outputId": "b31915b0-0a85-45d1-dbc9-0d7be7fe75d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 31/31 [00:00<00:00, 525.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for training_example in tqdm(training_data):\n",
        "    text = training_example['text']\n",
        "    labels = training_example['entities']\n",
        "    doc = nlp.make_doc(text)\n",
        "    ents = []\n",
        "    for start, end, label in labels:\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            print(\"Skipping entity\")\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    filtered_ents = filter_spans(ents)\n",
        "    doc.set_ents(filtered_ents)\n",
        "    doc_bin.add(doc)\n",
        "\n",
        "doc_bin.to_disk(\"train.spacy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 4: Model Training\n",
        "This section creates a training configuration and trains a custom spaCy NER model using the prepared training data.\n",
        "\n",
        "### 1. Initialize Training Configuration\n",
        "**Command Breakdown**:\n",
        "- **`python -m spacy`**: Runs spaCy as a Python module\n",
        "- **`init config`**: Creates a training configuration file\n",
        "- **`config.cfg`**: Output filename for the configuration\n",
        "- **`--lang en`**: Sets the language to English\n",
        "- **`--pipeline ner`**: Specifies that only the NER component should be included\n",
        "- **`--optimize efficiency`**: Optimizes for faster training and smaller model size (alternative: `accuracy` for better performance)\n",
        "\n",
        "**What it Creates**:\n",
        "A `config.cfg` file containing:\n",
        "- Model architecture settings\n",
        "- Training hyperparameters\n",
        "- Pipeline component configurations\n",
        "- Optimizer settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOKnia6RPUkD",
        "outputId": "daa513eb-f507-4dff-e608-cad3bb762ddb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;3m⚠ To generate a more effective transformer-based config (GPU-only),\n",
            "install the spacy-transformers package and re-run this command. The config\n",
            "generated now does not use transformers.\u001b[0m\n",
            "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
            "- Language: en\n",
            "- Pipeline: ner\n",
            "- Optimize for: efficiency\n",
            "- Hardware: CPU\n",
            "- Transformer: None\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ],
      "source": [
        "! python -m spacy init config config.cfg --lang en --pipeline ner --optimize efficiency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 2. Train the Model\n",
        "\n",
        "**Command Breakdown**:\n",
        "- **`spacy train`**: Initiates the training process\n",
        "- **`config.cfg`**: Uses the configuration file created in step 1\n",
        "- **`--output ./`**: Saves trained models to the current directory\n",
        "- **`--paths.train ./train.spacy`**: Specifies the training data file\n",
        "- **`--paths.dev ./train.spacy`**: Specifies the development/validation data file\n",
        "\n",
        "**Note**: In this code, the same file is used for both training and development. Ideally, you should split your data into separate training and validation sets.\n",
        "\n",
        "**Training Process**:\n",
        "1. **Loads the configuration** and training data\n",
        "2. **Initializes the model** with random weights\n",
        "3. **Trains iteratively**:\n",
        "   - Processes batches of training examples\n",
        "   - Computes loss (prediction error)\n",
        "   - Updates model weights via backpropagation\n",
        "   - Evaluates on development set\n",
        "4. **Saves checkpoints**:\n",
        "   - `model-best/`: The model with the best validation performance\n",
        "   - `model-last/`: The model from the final training iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjekvEBAPZ1W",
        "outputId": "75b8e781-102b-49cf-c929-512c383673e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;4mℹ Saving to output directory: .\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00    153.29    0.00    0.00    0.00    0.00\n",
            "  7     200        734.73   3155.19   76.73   79.66   74.02    0.77\n",
            " 14     400        596.12    731.85   95.69   95.31   96.06    0.96\n",
            " 22     600        842.19    276.60   96.84   97.22   96.46    0.97\n",
            " 30     800        177.29    181.67   98.03   98.03   98.03    0.98\n",
            " 40    1000        172.56    176.14   98.43   98.43   98.43    0.98\n",
            " 51    1200        793.37    172.28   98.22   98.80   97.64    0.98\n",
            " 65    1400        187.19    181.08   98.43   98.43   98.43    0.98\n",
            " 81    1600        162.25    176.52   98.43   98.43   98.43    0.98\n",
            "101    1800        108.62    182.21   98.43   98.43   98.43    0.98\n",
            "127    2000       4670.39    284.23   98.82   98.44   99.21    0.99\n",
            "159    2200        186.94    233.42   98.82   98.82   98.82    0.99\n",
            "198    2400        184.86    249.95   98.82   98.82   98.82    0.99\n",
            "246    2600        154.46    270.05   98.82   98.82   98.82    0.99\n",
            "295    2800        268.95    307.13   98.82   98.82   98.82    0.99\n",
            "345    3000        111.40    269.79   98.82   98.44   99.21    0.99\n",
            "393    3200         68.35    253.85   98.81   99.21   98.43    0.99\n",
            "443    3400         81.66    252.48   98.82   98.44   99.21    0.99\n",
            "492    3600        135.87    268.31   98.81   99.21   98.43    0.99\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "model-last\n"
          ]
        }
      ],
      "source": [
        "! python -m spacy train config.cfg --output ./ --paths.train ./train.spacy --paths.dev ./train.spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Load Trained Model\n",
        "- Loads the best performing model from disk\n",
        "- Creates a ready-to-use spaCy pipeline for predictions\n",
        "\n",
        "**Metrics Explained**:\n",
        "- **LOSS NER**: Training loss (lower is better)\n",
        "- **ENTS_F**: F1-score (harmonic mean of precision and recall)\n",
        "- **ENTS_P**: Precision (percentage of predicted entities that are correct)\n",
        "- **ENTS_R**: Recall (percentage of actual entities that were found)\n",
        "- **SCORE**: Overall score used to select the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "AoagyUYrPiQH"
      },
      "outputs": [],
      "source": [
        "nlp_trained_model = spacy.load(\"model-best\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 5: Model Inference with spaCy\n",
        "\n",
        "This section demonstrates how to use the trained custom spaCy model to perform Named Entity Recognition on new medical text.\n",
        "\n",
        "### 1. Test with Sample Text \n",
        "\n",
        "**Process**:\n",
        "- Passes medical text through the trained model\n",
        "- The model tokenizes the text and identifies entities\n",
        "- Returns a `Doc` object containing tokens, entities, and other linguistic features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "HTROMjfvPmig"
      },
      "outputs": [],
      "source": [
        "doc = nlp_trained_model('''\n",
        "The patient was prescribed Aspirin for their heart condition.\n",
        "The doctor recommended Ibuprofen to alleviate the patient's headache.\n",
        "The patient is suffering from diabetes, and they need to take Metformin regularly.\n",
        "After the surgery, the patient experienced some post-operative complications, including infection.\n",
        "The patient is currently on a regimen of Lisinopril to manage their high blood pressure.\n",
        "The antibiotic course for treating the bacterial infection should be completed as prescribed.\n",
        "The patient's insulin dosage needs to be adjusted to better control their blood sugar levels.\n",
        "The physician suspects that the patient may have pneumonia and has ordered a chest X-ray.\n",
        "The patient's cholesterol levels are high, and they have been advised to take Atorvastatin.\n",
        "The allergy to penicillin was noted in the patient's medical history.\n",
        "''')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Visualize Entities (Colab)\n",
        "- Uses spaCy's built-in visualizer to display entities\n",
        "- `style=\"ent\"`: Renders Named Entities\n",
        "- `jupyter=True`: Outputs directly in Jupyter/Colab notebooks\n",
        "- Highlights entities with different colors based on their labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "rd_TcnE4PqNd",
        "outputId": "268149b9-9fc6-4ebc-8707-7bc78dcefbdf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"><br>The patient was prescribed Aspirin for their heart condition.<br>The doctor recommended Ibuprofen to alleviate the patient's \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    headache\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MEDICALCONDITION</span>\n",
              "</mark>\n",
              ".<br>The patient is \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    suffering\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MEDICALCONDITION</span>\n",
              "</mark>\n",
              " from diabetes, and they need to take Metformin \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    regularly\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MEDICALCONDITION</span>\n",
              "</mark>\n",
              ".<br>After the surgery, the patient experienced some post-operative complications, including infection.<br>The patient is currently on a regimen of Lisinopril to manage their high blood pressure.<br>The antibiotic course for treating the bacterial infection should be completed as prescribed.<br>The patient's \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    insulin\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MEDICINE</span>\n",
              "</mark>\n",
              " dosage needs to be adjusted to better control their blood sugar levels.<br>The physician suspects that the patient may have pneumonia and has ordered a \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    chest X-ray.\n",
              "The patient's cholesterol\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MEDICALCONDITION</span>\n",
              "</mark>\n",
              " levels are high, and they have been advised to take Atorvastatin.<br>The allergy to penicillin was noted in the patient's medical history.<br></div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "spacy.displacy.render(doc, style=\"ent\", jupyter=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Load Model from Local Path\n",
        "- Shows how to load the model from a local Windows path (outside Colab)\n",
        "- Useful for deploying the model in a different environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "model_best = r\"E:\\NLP\\NLP with Sequence Models\\LSTM and Named Entity Recognition\\Medical NER Application\\model-best\"\n",
        "nlp_trained_model = spacy.load(model_best)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Test with Different Medical Text\n",
        "- Tests the model with a new set of medical sentences\n",
        "- Validates the model's ability to generalize to unseen text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "doc = nlp_trained_model('''\n",
        "The patient was prescribed Warfarin to prevent blood clots.\n",
        "The physician recommended Acetaminophen for managing the patient's fever.\n",
        "The patient has been diagnosed with chronic obstructive pulmonary disease (COPD) and requires inhaler therapy.\n",
        "Following the appendectomy, the patient showed signs of mild inflammation.\n",
        "The patient is on Atorvastatin to control elevated cholesterol levels.\n",
        "Completing the full course of Amoxicillin is essential for treating the bacterial infection.\n",
        "The endocrinologist adjusted the patient's Levothyroxine dosage to regulate thyroid function.\n",
        "A chest CT scan was ordered to investigate suspected pulmonary embolism.\n",
        "The patient was counseled on diet and exercise to manage their hypertension.\n",
        "A documented allergy to Sulfa drugs was noted in the medical records.\n",
        "''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Star\\AppData\\Local\\Temp\\ipykernel_9044\\2443853978.py:4: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
            "  from IPython.core.display import display, HTML\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"><br>The patient was prescribed Warfarin to prevent blood clots.<br>The physician recommended Acetaminophen for managing the patient's fever.<br>The patient has been diagnosed with chronic obstructive pulmonary disease (COPD) and \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    requires inhaler therapy\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MEDICALCONDITION</span>\n",
              "</mark>\n",
              ".<br>Following the appendectomy, the patient showed signs of mild inflammation.<br>The patient is on Atorvastatin to control elevated cholesterol levels.<br>Completing the full course of \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Amoxicillin\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MEDICINE</span>\n",
              "</mark>\n",
              " is essential for treating the bacterial infection.<br>The endocrinologist adjusted the patient's Levothyroxine dosage to regulate thyroid function.<br>A chest CT scan was ordered to investigate suspected pulmonary \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    embolism\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MEDICALCONDITION</span>\n",
              "</mark>\n",
              ".<br>The patient was counseled on diet and exercise to manage their hypertension.<br>A documented allergy to Sulfa drugs was noted in the medical records.<br></div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# spacy.displacy.render(doc, style=\"ent\", jupyter=True)\n",
        "# from spacy import displacy\n",
        "from spacy import displacy\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "html = displacy.render(doc, style=\"ent\")\n",
        "display(HTML(html))\n",
        "\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 6: Transformer Model Inference\n",
        "This section uses a pre-trained biomedical NER model from Hugging Face's Transformers library as an alternative to the custom-trained spaCy model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Import Required Libraries\n",
        "- Imports PyTorch libraries (the backend for Transformers)\n",
        "- **Note**: Only `torch` is actually needed; `torchvision` and `torchaudio` are imported but not used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch \n",
        "import torchvision \n",
        "import torchaudio "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Load Pre-trained Model and Tokenizer\n",
        "\n",
        "**Components**:\n",
        "- **AutoTokenizer**: Converts text into tokens (subword units) that the model understands\n",
        "- **AutoModelForTokenClassification**: A transformer model fine-tuned for token classification (NER)\n",
        "- **Model ID**: `\"d4data/biomedical-ner-all\"` is a pre-trained model specialized for biomedical text\n",
        "\n",
        "**What happens behind the scenes**:\n",
        "1. Downloads the model weights from Hugging Face Hub (cached locally after first download)\n",
        "2. Loads the tokenizer configuration (vocabulary, special tokens, etc.)\n",
        "3. Initializes the model architecture and loads pre-trained weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\NLP\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "e:\\NLP\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Star\\.cache\\huggingface\\hub\\models--d4data--biomedical-ner-all. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"d4data/biomedical-ner-all\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"d4data/biomedical-ner-all\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Create NER Pipeline\n",
        "\n",
        "**Pipeline Configuration**:\n",
        "- **`\"ner\"`**: Specifies this is a Named Entity Recognition task\n",
        "- **`model=model`**: Uses the loaded model\n",
        "- **`tokenizer=tokenizer`**: Uses the loaded tokenizer\n",
        "- **`aggregation_strategy=\"simple\"`**: Combines subword tokens into complete words\n",
        "  - Without this, \"Warfarin\" might be split into [\"War\", \"##far\", \"##in\"]\n",
        "  - With this, you get a single entity for \"Warfarin\"\n",
        "\n",
        "**Optional**: Add `device=0` to use GPU: `pipeline(..., device=0)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\") # pass device=0 if using gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Perform Entity Recognition\n",
        "\n",
        "**Process**:\n",
        "1. Text is tokenized into subwords\n",
        "2. Tokens are passed through the transformer model\n",
        "3. Model predicts entity labels for each token\n",
        "4. Labels are aggregated back into word-level entities\n",
        "5. Returns a list of dictionaries with entity information\n",
        "\n",
        "**Fields**:\n",
        "- **`entity_group`**: The type of entity (CHEMICAL, DISEASE, GENE, etc.)\n",
        "- **`score`**: Confidence score (0-1)\n",
        "- **`word`**: The actual entity text\n",
        "- **`start`/`end`**: Character positions in the original text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'entity_group': 'Medication',\n",
              "  'score': np.float32(0.99672157),\n",
              "  'word': 'warfarin',\n",
              "  'start': 28,\n",
              "  'end': 36},\n",
              " {'entity_group': 'Medication',\n",
              "  'score': np.float32(0.99865365),\n",
              "  'word': 'ace',\n",
              "  'start': 87,\n",
              "  'end': 90},\n",
              " {'entity_group': 'Medication',\n",
              "  'score': np.float32(0.9869897),\n",
              "  'word': '##tam',\n",
              "  'start': 90,\n",
              "  'end': 93},\n",
              " {'entity_group': 'Medication',\n",
              "  'score': np.float32(0.9743514),\n",
              "  'word': '##inophen',\n",
              "  'start': 93,\n",
              "  'end': 100},\n",
              " {'entity_group': 'Disease_disorder',\n",
              "  'score': np.float32(0.6789561),\n",
              "  'word': 'pulmonary disease',\n",
              "  'start': 191,\n",
              "  'end': 208},\n",
              " {'entity_group': 'Disease_disorder',\n",
              "  'score': np.float32(0.99904937),\n",
              "  'word': 'cop',\n",
              "  'start': 210,\n",
              "  'end': 213},\n",
              " {'entity_group': 'Medication',\n",
              "  'score': np.float32(0.999882),\n",
              "  'word': 'at',\n",
              "  'start': 339,\n",
              "  'end': 341},\n",
              " {'entity_group': 'Medication',\n",
              "  'score': np.float32(0.9997048),\n",
              "  'word': '##or',\n",
              "  'start': 341,\n",
              "  'end': 343},\n",
              " {'entity_group': 'Medication',\n",
              "  'score': np.float32(0.89418775),\n",
              "  'word': '##vastatin',\n",
              "  'start': 343,\n",
              "  'end': 351},\n",
              " {'entity_group': 'Medication',\n",
              "  'score': np.float32(0.9998727),\n",
              "  'word': 'am',\n",
              "  'start': 422,\n",
              "  'end': 424},\n",
              " {'entity_group': 'Medication',\n",
              "  'score': np.float32(0.9781475),\n",
              "  'word': '##oxicillin',\n",
              "  'start': 424,\n",
              "  'end': 433},\n",
              " {'entity_group': 'Subject',\n",
              "  'score': np.float32(0.4236932),\n",
              "  'word': 'end',\n",
              "  'start': 489,\n",
              "  'end': 492},\n",
              " {'entity_group': 'Medication',\n",
              "  'score': np.float32(0.9995409),\n",
              "  'word': 'lev',\n",
              "  'start': 528,\n",
              "  'end': 531},\n",
              " {'entity_group': 'Medication',\n",
              "  'score': np.float32(0.88453287),\n",
              "  'word': '##othyroxine',\n",
              "  'start': 531,\n",
              "  'end': 541},\n",
              " {'entity_group': 'Biological_structure',\n",
              "  'score': np.float32(0.9999167),\n",
              "  'word': 'chest',\n",
              "  'start': 581,\n",
              "  'end': 586},\n",
              " {'entity_group': 'Diagnostic_procedure',\n",
              "  'score': np.float32(0.99989736),\n",
              "  'word': 'ct',\n",
              "  'start': 587,\n",
              "  'end': 589},\n",
              " {'entity_group': 'Biological_structure',\n",
              "  'score': np.float32(0.994873),\n",
              "  'word': 'pulmonary',\n",
              "  'start': 632,\n",
              "  'end': 641},\n",
              " {'entity_group': 'Therapeutic_procedure',\n",
              "  'score': np.float32(0.74403876),\n",
              "  'word': 'diet',\n",
              "  'start': 681,\n",
              "  'end': 685},\n",
              " {'entity_group': 'Therapeutic_procedure',\n",
              "  'score': np.float32(0.5597369),\n",
              "  'word': 'exercise',\n",
              "  'start': 690,\n",
              "  'end': 698},\n",
              " {'entity_group': 'History',\n",
              "  'score': np.float32(0.8948173),\n",
              "  'word': 'all',\n",
              "  'start': 742,\n",
              "  'end': 745},\n",
              " {'entity_group': 'History',\n",
              "  'score': np.float32(0.7259436),\n",
              "  'word': '##ergy',\n",
              "  'start': 745,\n",
              "  'end': 749},\n",
              " {'entity_group': 'Medication',\n",
              "  'score': np.float32(0.8368515),\n",
              "  'word': 'sulfa',\n",
              "  'start': 753,\n",
              "  'end': 758}]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe(\"\"\"\n",
        "The patient was prescribed Warfarin to prevent blood clots.\n",
        "The physician recommended Acetaminophen for managing the patient's fever.\n",
        "The patient has been diagnosed with chronic obstructive pulmonary disease (COPD) and requires inhaler therapy.\n",
        "Following the appendectomy, the patient showed signs of mild inflammation.\n",
        "The patient is on Atorvastatin to control elevated cholesterol levels.\n",
        "Completing the full course of Amoxicillin is essential for treating the bacterial infection.\n",
        "The endocrinologist adjusted the patient's Levothyroxine dosage to regulate thyroid function.\n",
        "A chest CT scan was ordered to investigate suspected pulmonary embolism.\n",
        "The patient was counseled on diet and exercise to manage their hypertension.\n",
        "A documented allergy to Sulfa drugs was noted in the medical records.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advantages of Pre-trained Models\n",
        "\n",
        "### 1. No Training Required\n",
        "- Model is already trained on large biomedical corpora\n",
        "- Can be used immediately without annotated data\n",
        "\n",
        "### 2. Broad Coverage\n",
        "The `biomedical-ner-all` model recognizes multiple entity types:\n",
        "- **Chemicals/Drugs**: Medications, compounds\n",
        "- **Diseases**: Conditions, symptoms\n",
        "- **Genes**: Gene names, proteins\n",
        "- **Species**: Organisms\n",
        "- **Cell Types**: Cellular components\n",
        "\n",
        "### 3. State-of-the-Art Performance\n",
        "- Based on transformer architecture (BERT, BioBERT, etc.)\n",
        "- Generally higher accuracy than simpler models\n",
        "- Better at handling context and ambiguity\n",
        "\n",
        "## Comparison: spaCy vs Transformers\n",
        "\n",
        "| Aspect | Custom spaCy Model | Pre-trained Transformer |\n",
        "|--------|-------------------|------------------------|\n",
        "| Training | Requires annotated data | Ready to use |\n",
        "| Speed | Fast inference | Slower (but more accurate) |\n",
        "| Customization | Fully customizable | Limited without fine-tuning |\n",
        "| Entity types | Only what you train | Pre-defined broad set |\n",
        "| Memory | Small footprint | Large (100s of MBs) |\n",
        "\n",
        "## Use Cases\n",
        "\n",
        "Best for:\n",
        "- **Quick prototyping**: Test NER without training\n",
        "- **Broad entity coverage**: Need many entity types\n",
        "- **High accuracy**: When precision is critical\n",
        "- **Limited training data**: Don't have enough annotations\n",
        "\n",
        "## Alternative Models\n",
        "\n",
        "Other popular biomedical NER models:\n",
        "- `dmis-lab/biobert-base-cased-v1.1`\n",
        "- `allenai/scibert_scivocab_uncased`\n",
        "- `microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract`\n",
        "\n",
        "Each specializes in different biomedical subdomains (clinical, research, etc.)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "NLP",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
